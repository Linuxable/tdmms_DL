{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: c:\\Users\\abell\\Documents\\aa_delft\\J4\\BEP\\ai\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from mrcnn.model import MaskRCNN, load_image_gt, mold_image\n",
    "from mrcnn.utils import compute_ap\n",
    "from tdmms.tdmcoco import CocoConfig\n",
    "from bep.utils import load_train_val_datasets\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "print('Root directory:',ROOT_DIR)\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NAME = 'inference'\n",
    "\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, 'logs', 'training')\n",
    "\n",
    "if not os.path.exists(DEFAULT_LOGS_DIR):\n",
    "    os.makedirs(DEFAULT_LOGS_DIR)\n",
    "    print(f\"Folder '{DEFAULT_LOGS_DIR}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_average_precision(dataset, inference_model):\n",
    "    mAPs = []\n",
    "    dataset_limit = len(dataset.image_ids)\n",
    "    dataset_image_ids = dataset.image_ids.copy()\n",
    "\n",
    "    # Use a random subset of the data when a limit is defined\n",
    "    np.random.shuffle(dataset_image_ids)\n",
    "\n",
    "    for image_id in dataset_image_ids[:dataset_limit]:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, inference_model.config, image_id)\n",
    "        molded_images = np.expand_dims(mold_image(image, inference_model.config), 0)\n",
    "        results = inference_model.detect(molded_images, verbose=0)\n",
    "        r = results[0]\n",
    "        \n",
    "        # Compute mAP - VOC uses IoU 0.5\n",
    "        AP, _, _, _ = compute_ap(\n",
    "            gt_bbox,\n",
    "            gt_class_id,\n",
    "            gt_mask,\n",
    "            r[\"rois\"],\n",
    "            r[\"class_ids\"],\n",
    "            r[\"scores\"],\n",
    "            r['masks']\n",
    "        )\n",
    "        mAPs.append(AP)\n",
    "\n",
    "    return np.array(mAPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test = load_train_val_datasets(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = InferenceConfig()\n",
    "inference_model = MaskRCNN(\n",
    "    mode=\"inference\",\n",
    "    config=config,\n",
    "    model_dir=DEFAULT_LOGS_DIR\n",
    ")\n",
    "\n",
    "inference_model.load_weights(os.path.join(ROOT_DIR, 'weights', '20241123-173838_nbse2_wte2_4_True_89_2__0113.h5'), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abell\\Documents\\aa_delft\\J4\\BEP\\ai\\env_tf24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (19,1048576) and (3136,10) not aligned: 1048576 (dim 1) != 3136 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mAPs \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mean_average_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAPs: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mAPs))\n\u001b[0;32m      3\u001b[0m mAP \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(mAPs)\n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mcalculate_mean_average_precision\u001b[1;34m(dataset, inference_model)\u001b[0m\n\u001b[0;32m     13\u001b[0m     r \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Compute mAP - VOC uses IoU 0.5\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     AP, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgt_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_class_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscores\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmasks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     mAPs\u001b[38;5;241m.\u001b[39mappend(AP)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(mAPs)\n",
      "File \u001b[1;32mc:\\Users\\abell\\Documents\\aa_delft\\J4\\BEP\\ai\\tdmms_DL\\mrcnn\\utils.py:698\u001b[0m, in \u001b[0;36mcompute_ap\u001b[1;34m(gt_boxes, gt_class_ids, gt_masks, pred_boxes, pred_class_ids, pred_scores, pred_masks, iou_threshold)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Average Precision at a set IoU threshold (default 0.5).\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;124;03mmAP: Mean Average Precision\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03moverlaps: [pred_boxes, gt_boxes] IoU overlaps.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;66;03m# Get matches and overlaps\u001b[39;00m\n\u001b[1;32m--> 698\u001b[0m gt_match, pred_match, overlaps \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_matches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgt_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_class_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_class_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Compute precision and recall at each prediction box step\u001b[39;00m\n\u001b[0;32m    704\u001b[0m precisions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(pred_match \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(pred_match)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\abell\\Documents\\aa_delft\\J4\\BEP\\ai\\tdmms_DL\\mrcnn\\utils.py:654\u001b[0m, in \u001b[0;36mcompute_matches\u001b[1;34m(gt_boxes, gt_class_ids, gt_masks, pred_boxes, pred_class_ids, pred_scores, pred_masks, iou_threshold, score_threshold)\u001b[0m\n\u001b[0;32m    651\u001b[0m pred_masks \u001b[38;5;241m=\u001b[39m pred_masks[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, indices]\n\u001b[0;32m    653\u001b[0m \u001b[38;5;66;03m# Compute IoU overlaps [pred_masks, gt_masks]\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m overlaps \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_overlaps_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# Loop through predictions and find matching ground truth boxes\u001b[39;00m\n\u001b[0;32m    657\u001b[0m match_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\abell\\Documents\\aa_delft\\J4\\BEP\\ai\\tdmms_DL\\mrcnn\\utils.py:103\u001b[0m, in \u001b[0;36mcompute_overlaps_masks\u001b[1;34m(masks1, masks2)\u001b[0m\n\u001b[0;32m    100\u001b[0m area2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(masks2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# intersections and union\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m intersections \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m union \u001b[38;5;241m=\u001b[39m area1[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m area2[\u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;241m-\u001b[39m intersections\n\u001b[0;32m    105\u001b[0m overlaps \u001b[38;5;241m=\u001b[39m intersections \u001b[38;5;241m/\u001b[39m union\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (19,1048576) and (3136,10) not aligned: 1048576 (dim 1) != 3136 (dim 0)"
     ]
    }
   ],
   "source": [
    "mAPs = calculate_mean_average_precision(test, inference_model)\n",
    "print('mAPs: {}'.format(mAPs))\n",
    "mAP = np.mean(mAPs)\n",
    "print('mean mAP: {}'.format(mAP))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
